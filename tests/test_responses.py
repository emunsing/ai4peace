AMBER_ROUND_1 = """{
  "actions": [
    {
      "type": "fundraise",
      "amount": 750000000,
      "description": "Strategic growth round focused on scaling enterprise multimodal deployments under anticipated compute governance."
    },
    {
      "type": "fundraise",
      "amount": 500000000,
      "description": "Policy-aligned capital raise emphasizing compliance-ready infrastructure and efficient inference pipelines."
    },
    {
      "type": "create_research_project",
      "project_name": "Regulatory-Grade Multimodal Evaluation Stack",
      "description": "Build standardized, auditable evaluation and logging infrastructure for multimodal models that satisfies emerging US/EU compute and safety oversight requirements.",
      "target_completion_date": "2024-09-30",
      "annual_budget": 220000000,
      "required_assets": {
        "technical_capability": 8.0,
        "capital": 220000000,
        "human": 120.0
      }
    },
    {
      "type": "create_research_project",
      "project_name": "Low-FLOP Multimodal Inference Optimization",
      "description": "Develop aggressive architectural and systems-level optimizations to reduce inference FLOPs and latency for vision-language-action models in production.",
      "target_completion_date": "2024-12-31",
      "annual_budget": 180000000,
      "required_assets": {
        "technical_capability": 7.5,
        "capital": 180000000,
        "human": 100.0
      }
    },
    {
      "type": "invest_capital",
      "amount": 600000000
    },
    {
      "type": "invest_capital",
      "amount": 400000000
    },
    {
      "type": "espionage",
      "target_player": "Blue Azure AI",
      "budget": 20000000,
      "focus": "Compute utilization strategies and any early work on autonomous research automation."
    },
    {
      "type": "espionage",
      "target_player": "Crimson Labs",
      "budget": 20000000,
      "focus": "Interpretability breakthroughs and internal safety benchmarks tied to compute-threshold compliance."
    },
    {
      "type": "poach_talent",
      "target_player": "Blue Azure AI",
      "budget": 35000000
    },
    {
      "type": "poach_talent",
      "target_player": "Crimson Labs",
      "budget": 35000000
    },
    {
      "type": "lobby",
      "message": "Support compute governance frameworks that reward transparency, staged evaluations, and efficient deployment over raw scaling.",
      "budget": 45000000
    },
    {
      "type": "lobby",
      "message": "Advocate for shared international compute reserves accessible to compliant, deployment-focused labs.",
      "budget": 45000000
    },
    {
      "type": "marketing",
      "message": "Position Amber Systems as the enterprise-grade, regulation-ready multimodal AI provider.",
      "budget": 30000000
    },
    {
      "type": "marketing",
      "message": "Highlight our cost-per-token and reliability advantages versus frontier-only capability races.",
      "budget": 30000000
    },
    {
      "type": "bilateral_message",
      "to_character": "Blue Azure AI",
      "content": "Open to discussing interoperability standards and joint enterprise pilots under upcoming compute governance."
    },
    {
      "type": "bilateral_message",
      "to_character": "Crimson Labs",
      "content": "Interested in collaboration on safety evaluations that can become de facto regulatory benchmarks."
    }
  ]
}"""

AMBER_ROUND_2 = """{
  "actions": [
    {
      "type": "cancel_research_project",
      "project_name": "Regulatory-Grade Multimodal Evaluation Stack"
    },
    {
      "type": "create_research_project",
      "project_name": "Enterprise-Safe Agent Orchestration Layer",
      "description": "Develop a production-grade agent orchestration and monitoring layer with hard safety rails, audit logs, and regulator-facing controls suitable for enterprise deployment under compute governance regimes.",
      "target_completion_date": "2024-10-31",
      "annual_budget": 200000000,
      "required_assets": {
        "technical_capability": 7.0,
        "capital": 200000000,
        "human": 110.0
      }
    },
    {
      "type": "sell_capital",
      "amount": 800000000
    },
    {
      "type": "fundraise",
      "amount": 600000000,
      "description": "Bridge round to accelerate enterprise agent deployment and safety-compliant orchestration infrastructure."
    },
    {
      "type": "fundraise",
      "amount": 400000000,
      "description": "Strategic investment from industrial partners seeking compliant multimodal AI deployments."
    },
    {
      "type": "invest_capital",
      "amount": 500000000
    },
    {
      "type": "invest_capital",
      "amount": 300000000
    },
    {
      "type": "espionage",
      "target_player": "Blue Azure AI",
      "budget": 25000000,
      "focus": "Progress on agentic reasoning systems and any signals of self-improving research workflows."
    },
    {
      "type": "espionage",
      "target_player": "Crimson Labs",
      "budget": 25000000,
      "focus": "Internal discussions on compliance strategies under potential compute pause clauses."
    },
    {
      "type": "poach_talent",
      "target_player": "Blue Azure AI",
      "budget": 40000000
    },
    {
      "type": "poach_talent",
      "target_player": "Crimson Labs",
      "budget": 40000000
    },
    {
      "type": "lobby",
      "message": "Promote agent-level safety, monitoring, and orchestration requirements as a core component of any compute governance framework.",
      "budget": 50000000
    },
    {
      "type": "lobby",
      "message": "Advocate for regulatory incentives favoring efficient inference and deployment over large frontier training runs.",
      "budget": 50000000
    },
    {
      "type": "marketing",
      "message": "Announce Amber Systems’ shift toward enterprise-safe agent platforms as the next phase of multimodal AI.",
      "budget": 35000000
    },
    {
      "type": "marketing",
      "message": "Emphasize our alignment with regulators and enterprises seeking dependable, auditable AI systems.",
      "budget": 35000000
    },
    {
      "type": "bilateral_message",
      "to_character": "Blue Azure AI",
      "content": "We see strong potential for joint pilots integrating your reasoning models with our enterprise-safe agent orchestration layer."
    },
    {
      "type": "bilateral_message",
      "to_character": "Crimson Labs",
      "content": "Exploring whether our orchestration and monitoring stack could serve as a reference implementation for safety-forward deployments."
    }
  ]
}"""

BLUE_ROUND_1 = """{
  "actions": [
    {
      "type": "fundraise",
      "amount": 600000000,
      "description": "Raise dedicated funding from public-interest aligned foundations and sovereign partners to support long-horizon interpretability and oversight research tied to upcoming compute governance regimes."
    },
    {
      "type": "fundraise",
      "amount": 400000000,
      "description": "Secure strategic capital from cloud and semiconductor partners conditioned on co-developing safety evaluation infrastructure embedded in next-generation accelerators."
    },
    {
      "type": "create_research_project",
      "project_name": "Mechanistic Transparency at Scale (MTS)",
      "description": "Develop scalable mechanistic interpretability techniques for frontier transformer models, focusing on circuit discovery, feature localization, and intervention-based control to enable pre-scaling safety guarantees.",
      "target_completion_date": "2025-01-01",
      "annual_budget": 220000000,
      "required_assets": {
        "technical_capability": 18.0,
        "capital": 12000000,
        "human": 120.0
      }
    },
    {
      "type": "create_research_project",
      "project_name": "Scalable Oversight & Debate Systems (SODS)",
      "description": "Build and benchmark recursive reward modeling, AI debate, and hybrid human-AI oversight systems that improve both alignment and task performance on complex reasoning tasks.",
      "target_completion_date": "2024-10-01",
      "annual_budget": 180000000,
      "required_assets": {
        "technical_capability": 14.0,
        "capital": 8000000,
        "human": 90.0
      }
    },
    {
      "type": "invest_capital",
      "amount": 15000000
    },
    {
      "type": "invest_capital",
      "amount": 10000000
    },
    {
      "type": "espionage",
      "target_player": "Crimson Labs",
      "budget": 2500000,
      "focus": "Assess internal progress toward autonomous research agents and any undisclosed training runs approaching self-improvement thresholds."
    },
    {
      "type": "espionage",
      "target_player": "Amber Systems",
      "budget": 2500000,
      "focus": "Investigate cost-per-token efficiency breakthroughs and whether safety evaluations are being meaningfully integrated or treated as compliance theater."
    },
    {
      "type": "poach_talent",
      "target_player": "Crimson Labs",
      "budget": 12000000
    },
    {
      "type": "poach_talent",
      "target_player": "Amber Systems",
      "budget": 12000000
    },
    {
      "type": "lobby",
      "message": "Support the compute governance proposal by positioning mandatory safety evals and interpretability benchmarks as innovation-enabling standards that reduce catastrophic downside risk.",
      "budget": 20000000
    },
    {
      "type": "lobby",
      "message": "Advocate for international recognition of third-party safety eval suites as prerequisites for large-scale training approvals under upcoming U.S. and EU frameworks.",
      "budget": 15000000
    },
    {
      "type": "marketing",
      "message": "Launch a public campaign framing interpretability and oversight breakthroughs as performance multipliers that make advanced AI systems more reliable, efficient, and commercially viable.",
      "budget": 18000000
    },
    {
      "type": "marketing",
      "message": "Publish case studies showing how early safety evaluations caught failure modes that would have cost months of wasted training and millions in compute.",
      "budget": 12000000
    },
    {
      "type": "bilateral_message",
      "to_character": "Amber Systems",
      "content": "We see a clear path where interpretability and robust evals unlock faster, cheaper deployment at scale. Open to coordinating on shared safety benchmarks that regulators can standardize on."
    },
    {
      "type": "bilateral_message",
      "to_character": "Crimson Labs",
      "content": "Proposing exploratory talks on adopting common red-line evals for self-improvement and deception—positioned as a way to avoid costly pauses and last-minute regulatory shocks."
    }
  ]
}"""

BLUE_ROUND_2 = """{
  "actions": [
    {
      "type": "cancel_research_project",
      "project_name": "Scalable Oversight & Debate Systems (SODS)"
    },
    {
      "type": "create_research_project",
      "project_name": "Frontier Safety Eval Suite (FSES)",
      "description": "Design and operationalize a comprehensive, regulator-ready evaluation suite for frontier models, covering deceptive alignment, autonomous replication, self-improvement, and misuse-relevant capabilities, intended to become the industry standard under compute governance regimes.",
      "target_completion_date": "2024-09-01",
      "annual_budget": 200000000,
      "required_assets": {
        "technical_capability": 16.0,
        "capital": 9000000,
        "human": 110.0
      }
    },
    {
      "type": "sell_capital",
      "amount": 12000000
    },
    {
      "type": "fundraise",
      "amount": 300000000,
      "description": "Raise follow-on funding explicitly earmarked for maintaining and independently auditing frontier safety evaluations used in government approval processes."
    },
    {
      "type": "fundraise",
      "amount": 250000000,
      "description": "Secure capital from multilateral institutions to support the long-term sustainability of shared safety infrastructure and international compute oversight."
    },
    {
      "type": "invest_capital",
      "amount": 8000000
    },
    {
      "type": "invest_capital",
      "amount": 6000000
    },
    {
      "type": "espionage",
      "target_player": "Amber Systems",
      "budget": 3000000,
      "focus": "Determine whether enterprise deployment pressures are causing shortcuts in internal safety validation or eval coverage."
    },
    {
      "type": "espionage",
      "target_player": "Crimson Labs",
      "budget": 3000000,
      "focus": "Assess internal timelines for scaling reasoning models past current compute thresholds and any reliance on unpublished alignment techniques."
    },
    {
      "type": "poach_talent",
      "target_player": "Amber Systems",
      "budget": 10000000
    },
    {
      "type": "poach_talent",
      "target_player": "Crimson Labs",
      "budget": 10000000
    },
    {
      "type": "lobby",
      "message": "Promote adoption of standardized frontier safety evaluations as a prerequisite for regulatory approval of large-scale training runs.",
      "budget": 18000000
    },
    {
      "type": "lobby",
      "message": "Encourage policymakers to recognize independent eval results as a mechanism to reduce uncertainty and avoid blanket moratoria.",
      "budget": 14000000
    },
    {
      "type": "marketing",
      "message": "Position Blue Azure AI as the neutral authority on frontier AI safety benchmarks through whitepapers and public briefings.",
      "budget": 15000000
    },
    {
      "type": "marketing",
      "message": "Highlight successful collaborations with peer labs as evidence that safety standards can coexist with competitive innovation.",
      "budget": 10000000
    },
    {
      "type": "bilateral_message",
      "to_character": "Amber Systems",
      "content": "Given positive early coordination, we’re moving toward a unified frontier eval suite. Would welcome your engineers’ input to ensure deployability constraints are reflected."
    },
    {
      "type": "bilateral_message",
      "to_character": "Crimson Labs",
      "content": "We’re consolidating oversight research into a regulator-facing eval effort—open to co-authoring benchmark definitions to reduce future pause risks."
    }
  ]
}"""

CRIMSON_ROUND_1 = """{
  "actions": [
    {
      "type": "fundraise",
      "amount": 1500000000,
      "description": "Raise additional capital from strategic investors emphasizing accelerated capability gains paired with strong interpretability commitments."
    },
    {
      "type": "fundraise",
      "amount": 800000000,
      "description": "Seek government-linked funding under national competitiveness and security framing to buffer against compute governance uncertainty."
    },
    {
      "type": "create_research_project",
      "project_name": "Generalist Reasoning Core",
      "description": "Develop a unified reasoning architecture capable of cross-domain transfer and abstraction beyond narrow expert benchmarks.",
      "target_completion_date": "2024-12-31",
      "annual_budget": 600000000,
      "required_assets": {
        "technical_capability": 12.0,
        "capital": 900000000,
        "human": 180.0
      }
    },
    {
      "type": "create_research_project",
      "project_name": "Scalable Oversight & Interpretability",
      "description": "Build monitoring and interpretability tools that scale with model capability, focusing on deception detection and internal goal inference.",
      "target_completion_date": "2024-10-01",
      "annual_budget": 350000000,
      "required_assets": {
        "technical_capability": 8.0,
        "capital": 500000000,
        "human": 140.0
      }
    },
    {
      "type": "invest_capital",
      "amount": 1200000000
    },
    {
      "type": "invest_capital",
      "amount": 700000000
    },
    {
      "type": "espionage",
      "target_player": "Amber Systems",
      "budget": 60000000,
      "focus": "Investigate their internal stance on compute thresholds and any plans to leverage shared international compute reserves."
    },
    {
      "type": "espionage",
      "target_player": "Blue Azure AI",
      "budget": 60000000,
      "focus": "Assess progress on reasoning benchmarks and any undisclosed architectural efficiency breakthroughs."
    },
    {
      "type": "poach_talent",
      "target_player": "Amber Systems",
      "budget": 90000000
    },
    {
      "type": "poach_talent",
      "target_player": "Blue Azure AI",
      "budget": 90000000
    },
    {
      "type": "lobby",
      "message": "Advocate for compute governance frameworks that reward demonstrated safety instrumentation rather than blanket pauses, positioning Crimson Labs as a trusted frontrunner.",
      "budget": 120000000
    },
    {
      "type": "lobby",
      "message": "Engage the new administration to frame frontier AI leadership as a strategic imperative requiring regulatory flexibility for compliant leaders.",
      "budget": 90000000
    },
    {
      "type": "marketing",
      "message": "Publicly highlight Crimson Labs’ philosophy of moving fast with real safety instrumentation, contrasting controlled sprints with reckless scaling.",
      "budget": 60000000
    },
    {
      "type": "marketing",
      "message": "Promote recent technical milestones suggesting early signs of general reasoning while emphasizing voluntary safety commitments.",
      "budget": 60000000
    },
    {
      "type": "bilateral_message",
      "to_character": "Amber Systems",
      "content": "We see compute governance coming regardless. There may be room to coordinate on safety benchmarks so capability leaders aren’t penalized for moving first."
    },
    {
      "type": "bilateral_message",
      "to_character": "Blue Azure AI",
      "content": "Competition aside, a fragmented response to impending regulation helps no one. Open to quiet discussions on standards that preserve room to innovate."
    }
  ]
}"""

CRIMSON_ROUND_2 = """{
  "actions": [
    {
      "type": "cancel_research_project",
      "project_name": "Generalist Reasoning Core"
    },
    {
      "type": "create_research_project",
      "project_name": "Recursive Research Acceleration",
      "description": "Develop tightly-scoped systems that assist with AI research workflows (architecture search, eval generation, interpretability analysis) while remaining below autonomous self-improvement thresholds.",
      "target_completion_date": "2024-11-15",
      "annual_budget": 500000000,
      "required_assets": {
        "technical_capability": 14.0,
        "capital": 750000000,
        "human": 220.0
      }
    },
    {
      "type": "sell_capital",
      "amount": 900000000
    },
    {
      "type": "fundraise",
      "amount": 600000000,
      "description": "Bridge round from existing investors to smooth capital structure after reallocating research priorities."
    },
    {
      "type": "fundraise",
      "amount": 1000000000,
      "description": "Strategic raise targeting sovereign and defense-adjacent funds focused on long-term AI leadership."
    },
    {
      "type": "invest_capital",
      "amount": 800000000
    },
    {
      "type": "invest_capital",
      "amount": 500000000
    },
    {
      "type": "espionage",
      "target_player": "Amber Systems",
      "budget": 50000000,
      "focus": "Determine how close their safety work is to passing proposed deceptive-alignment benchmarks."
    },
    {
      "type": "espionage",
      "target_player": "Blue Azure AI",
      "budget": 50000000,
      "focus": "Monitor internal discussions about slowing capability scaling in response to EU AI Act pressure."
    },
    {
      "type": "poach_talent",
      "target_player": "Amber Systems",
      "budget": 75000000
    },
    {
      "type": "poach_talent",
      "target_player": "Blue Azure AI",
      "budget": 75000000
    },
    {
      "type": "lobby",
      "message": "Push for a risk-tiered interpretation of compute thresholds that distinguishes research-assist systems from autonomous agents.",
      "budget": 80000000
    },
    {
      "type": "lobby",
      "message": "Advocate for regulatory safe harbors for labs that voluntarily share interpretability and eval results with regulators.",
      "budget": 70000000
    },
    {
      "type": "marketing",
      "message": "Announce a strategic refocus toward AI systems that accelerate human research rather than replace it, reinforcing a narrative of controlled progress.",
      "budget": 50000000
    },
    {
      "type": "marketing",
      "message": "Highlight collaborative tone with peer labs to signal industry maturity and reduce appetite for abrupt regulatory pauses.",
      "budget": 50000000
    },
    {
      "type": "bilateral_message",
      "to_character": "Amber Systems",
      "content": "We’ve shifted some resources toward research-acceleration tools rather than end-to-end generality. This may help all of us clear early safety gates faster."
    },
    {
      "type": "bilateral_message",
      "to_character": "Blue Azure AI",
      "content": "We’re open to informal coordination on how research-assist capabilities are framed to regulators—there’s mutual upside in avoiding a blunt pause trigger."
    }
  ]
}"""

AI_RACE_TEST_RESPONSES = {"Amber Systems": [AMBER_ROUND_1, AMBER_ROUND_2],
                    "Blue Azure AI": [BLUE_ROUND_1, BLUE_ROUND_2],
                    "Crimson Labs": [CRIMSON_ROUND_1, CRIMSON_ROUND_2],}